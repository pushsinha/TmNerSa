{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re \n",
    "import nltk\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, StringType, ArrayType\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lower, col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "         .appName(\"big-data-project\") \\\n",
    "         .getOrCreate()\n",
    "\n",
    "# data = spark.read.csv(\"gnm_comments.csv\", header=True) #gives a dataframe\n",
    "\n",
    "# data = spark.sparkContext.textFile('gnm_articles.csv') #gives an rdd\n",
    "\n",
    "data = spark.read.csv(\"SFU_constructiveness_toxicity_corpus.csv\", header=True) #gives a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+---------+\n",
      "|        comment_text|is_constructive|sentiment|\n",
      "+--------------------+---------------+---------+\n",
      "|while technology ...|            yes|      1.0|\n",
      "|everyone is still...|            yes|      1.0|\n",
      "|you've never used...|             no|      0.0|\n",
      "|you may be using ...|             no|      0.0|\n",
      "|of course we all ...|             no|      0.0|\n",
      "|simpson claims th...|            yes|      1.0|\n",
      "|we have multiple ...|            yes|      1.0|\n",
      "|a good start to s...|            yes|      1.0|\n",
      "|all of this energ...|            yes|      1.0|\n",
      "|time for the elde...|            yes|      1.0|\n",
      "|canada has done m...|             no|      0.0|\n",
      "|a few of the comm...|            yes|      1.0|\n",
      "|there is a differ...|            yes|      1.0|\n",
      "|it's absolutely n...|            yes|      1.0|\n",
      "|i honestly cannot...|            yes|      1.0|\n",
      "|why does the glob...|             no|      0.0|\n",
      "|playing the race ...|             no|      0.0|\n",
      "|the historic head...|            yes|      1.0|\n",
      "|one big differenc...|            yes|      1.0|\n",
      "|what a stupid art...|             no|      0.0|\n",
      "|i live in quebec,...|            yes|      1.0|\n",
      "|this whole concep...|            yes|      1.0|\n",
      "|last week it was ...|            yes|      1.0|\n",
      "|in ontario the cr...|            yes|      1.0|\n",
      "|while i support t...|            yes|      1.0|\n",
      "|the author knows ...|            yes|      1.0|\n",
      "|simpson is right:...|            yes|      1.0|\n",
      "|harper promised 1...|            yes|      1.0|\n",
      "|it's easy to comp...|            yes|      1.0|\n",
      "|a great plan, but...|            yes|      1.0|\n",
      "+--------------------+---------------+---------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = data.select(['comment_text','is_constructive'])\n",
    "data2 = data2.where(col(\"comment_text\").isNotNull())\n",
    "# data2.show()\n",
    "\n",
    "def sentiment(x):\n",
    "    if x=='yes': \n",
    "        return float(1)\n",
    "    else: \n",
    "        return float(0)\n",
    "\n",
    "sentiment_udf = udf(lambda x: sentiment(x), FloatType())\n",
    "data2 = data2.withColumn(\"sentiment\", sentiment_udf(\"is_constructive\"))\n",
    "\n",
    "data2 = data2.withColumn(\"comment_text\", lower(col(\"comment_text\")))\n",
    "\n",
    "data2.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, validation_set) = data2.randomSplit([0.7,0.3], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "|        comment_text|     is_constructive|sentiment|               words|                  tf|            features|label|\n",
      "+--------------------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "| but this last pa...|                null|      0.0|[, but, this, las...|(65536,[1518,3331...|(65536,[1518,3331...|  1.0|\n",
      "|      !!!!!!!!!!!!!!|                  no|      0.0|    [!!!!!!!!!!!!!!]|(65536,[27630],[1...|(65536,[27630],[0...|  1.0|\n",
      "|!!!!!''turks shoo...|                  no|      0.0|[!!!!!''turks, sh...|(65536,[8436,1045...|(65536,[8436,1045...|  1.0|\n",
      "|\"\"\"canada's carte...|                  no|      0.0|[\"\"\"canada's, car...|(65536,[1752,2820...|(65536,[1752,2820...|  1.0|\n",
      "|\"\"\"union bosses\"\"...|                  no|      0.0|[\"\"\"union, bosses...|(65536,[170,637,1...|(65536,[170,637,1...|  1.0|\n",
      "|\"@informed albert...| this is an artic...|      0.0|[\"@informed, albe...|(65536,[3331,8436...|(65536,[3331,8436...|  1.0|\n",
      "|\"afer14: and do y...|                  no|      0.0|[\"afer14:, and, d...|(65536,[513,2089,...|(65536,[513,2089,...|  1.0|\n",
      "|\"alexander slimni...| it can also fall...|      0.0|[\"alexander, slim...|(65536,[4054,9639...|(65536,[4054,9639...|  1.0|\n",
      "|\"david, don't ass...|      Thomas Toronto|      0.0|[\"david,, don't, ...|(65536,[3331,3395...|(65536,[3331,3395...|  1.0|\n",
      "|\"in the uber \"\"fr...|       certification|      0.0|[\"in, the, uber, ...|(65536,[7322,1633...|(65536,[7322,1633...|  1.0|\n",
      "|\"um, what? how ex...| what SPECIFIC th...|      0.0|[\"um,, what?, how...|(65536,[4882,5988...|(65536,[4882,5988...|  1.0|\n",
      "|\"what is this big...| how many were pe...|      0.0|[\"what, is, this,...|(65536,[4488,5381...|(65536,[4488,5381...|  1.0|\n",
      "|' ... all of whic...|                  no|      0.0|[', ..., all, of,...|(65536,[4488,7984...|(65536,[4488,7984...|  1.0|\n",
      "|' and we still ha...|                  no|      0.0|[', and, we, stil...|(65536,[418,3924,...|(65536,[418,3924,...|  1.0|\n",
      "|' but a serious a...|                 yes|      1.0|[', but, a, serio...|(65536,[3331,3795...|(65536,[3331,3795...|  0.0|\n",
      "|' nothing like th...|                  no|      0.0|[', nothing, like...|(65536,[1903,7748...|(65536,[1903,7748...|  1.0|\n",
      "|' so with prime m...|                 yes|      1.0|[', so, with, pri...|(65536,[886,1481,...|(65536,[886,1481,...|  0.0|\n",
      "|'... a larger que...|                 yes|      1.0|['..., a, larger,...|(65536,[1622,2041...|(65536,[1622,2041...|  0.0|\n",
      "|'...the people wh...|                  no|      0.0|['...the, people,...|(65536,[8436,1165...|(65536,[8436,1165...|  1.0|\n",
      "|'a trump administ...|                 yes|      1.0|['a, trump, admin...|(65536,[3331,3877...|(65536,[3331,3877...|  0.0|\n",
      "+--------------------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "validation_df = pipelineFit.transform(validation_set)\n",
    "train_df.count()\n",
    "train_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(validation_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+--------------------+\n",
      "|        comment_text|sentiment|label|       rawPrediction|\n",
      "+--------------------+---------+-----+--------------------+\n",
      "|             \"\"\"what|      0.0|  1.0|[-16.556949459227...|\n",
      "|\"of course you ig...|      0.0|  1.0|[8.58827612161051...|\n",
      "|' the problem is ...|      0.0|  1.0|[5.77610890326717...|\n",
      "|'''rouba al-fatta...|      1.0|  0.0|[-2.2271023186132...|\n",
      "|'...whether the f...|      0.0|  1.0|[-29.457463998710...|\n",
      "|'he’s hardly the ...|      1.0|  0.0|[22.6459438700175...|\n",
      "|'he’s hardly the ...|      1.0|  0.0|[67.1813873056786...|\n",
      "|'honey, do you re...|      0.0|  1.0|[3.10616648978955...|\n",
      "|'if she was a man...|      1.0|  0.0|[34.0667181172660...|\n",
      "|'the world has co...|      0.0|  1.0|[-12.061915383038...|\n",
      "|'this $37-billion...|      1.0|  0.0|[48.6080923891138...|\n",
      "|'what future do r...|      1.0|  0.0|[-1.1694210706198...|\n",
      "|'yes to uber. no ...|      0.0|  1.0|[-38.883508202324...|\n",
      "|a few of the comm...|      1.0|  0.0|[48.3005407012597...|\n",
      "|a good friend who...|      1.0|  0.0|[40.6088334273420...|\n",
      "|a national border...|      1.0|  0.0|[63.5427860074052...|\n",
      "|aa another soar l...|      0.0|  1.0|[-10.102956292118...|\n",
      "|according to g&m ...|      0.0|  1.0|[-23.144216396054...|\n",
      "|agreed, time to c...|      0.0|  1.0|[16.9290159385031...|\n",
      "|already we see ho...|      1.0|  0.0|[41.8455629354834...|\n",
      "+--------------------+---------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(['comment_text','sentiment','label','rawPrediction']).show()\n",
    "trainingSummary = lrModel.summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7995129870129875"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
